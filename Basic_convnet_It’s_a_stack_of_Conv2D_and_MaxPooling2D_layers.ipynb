{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic convnet. It’s a stack of Conv2D and MaxPooling2D layers",
      "provenance": [],
      "authorship_tag": "ABX9TyNqoRFmeaSFz913duJ0bbUK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIKEPY101/End-to-End-Machine-Learning-Project/blob/master/Basic_convnet_It%E2%80%99s_a_stack_of_Conv2D_and_MaxPooling2D_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsUuz_yOHIfv",
        "colab_type": "text"
      },
      "source": [
        "# Basic convnet. It’s a stack of Conv2D and MaxPooling2D layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjZAOjY1BSZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiating a small convnet\n",
        "from keras import layers\n",
        "from keras import models\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1MrR-BsIYgo",
        "colab_type": "text"
      },
      "source": [
        "### A convnet takes as input tensors of shape (image_height, image_width, image_channels) (not including the batch dimension). In this case, we’ll configure the convnet to process inputs of size (28, 28, 1), which is the format of MNIST images. We’ll do this by passing the argument input_shape=(28, 28, 1) to the first layer. Let’s display the architecture of the convnet so far:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iGZBGhKCi7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "4ae373f6-4fac-4a3d-a921-62909c53c4ab"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQB_BPKZI4qS",
        "colab_type": "text"
      },
      "source": [
        "### You can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). The width and height dimensions tend to shrink as you go deeper in the network. \n",
        "\n",
        "### The number of channels is controlled by the first argument passed to the Conv2D layers (32 or 64). \n",
        "\n",
        "### The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely connected classifier network; a stack of Dense layers. These classifiers process vectors, which are 1D, whereas the current output is a 3D tensor. \n",
        "\n",
        "### First we have to flatten the 3D outputs to 1D, and then add a few Dense layers on top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBpdjTNVCpR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding a classifier on top of the convnet\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHWkYsIoKsf8",
        "colab_type": "text"
      },
      "source": [
        "### We’ll do 10-way classification, using a final layer with 10 outputs and a softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jiyx16pC9bN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "636ca498-9b7f-4b19-b48f-fcd5a65eda88"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilq4m8ezLHwg",
        "colab_type": "text"
      },
      "source": [
        "### The (3, 3, 64) outputs are flattened into vectors of shape (576,) before going through two Dense layers. Now, let’s train the convnet on the MNIST digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opeuU6cEDVfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "83360d98-5386-409d-8c5d-9164603d1b10"
      },
      "source": [
        "# Training the convnet on MNIST images\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 0.1705 - accuracy: 0.9469\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 47s 50ms/step - loss: 0.0463 - accuracy: 0.9858\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 47s 50ms/step - loss: 0.0322 - accuracy: 0.9897\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 47s 50ms/step - loss: 0.0239 - accuracy: 0.9923\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 47s 50ms/step - loss: 0.0195 - accuracy: 0.9942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9fcdfa7cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mXrfWGZDsFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d6d431fb-6699-4b6a-f740-1ec163edfaf0"
      },
      "source": [
        "# Let’s evaluate the model on the test data:\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0353 - accuracy: 0.9892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9891999959945679"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7iBnQtvM6fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}